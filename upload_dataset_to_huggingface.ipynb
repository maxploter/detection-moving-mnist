{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6c142e38ed7ee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:32:05.485010Z",
     "start_time": "2025-06-02T12:32:02.829003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimploter/miniconda3/envs/detection-moving-mnist/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Video\n",
    "\n",
    "dataset = load_dataset(\"mmnist-dataset/huggingface-arrow-format/mmnist-easy\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "id": "50b88c0312a6f70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:01:48.165313Z",
     "start_time": "2025-07-10T08:01:42.269692Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.ops import box_iou\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "version = 'medium'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(f\"mmnist-dataset/huggingface-arrow-format/mmnist-{version}\")\n",
    "\n",
    "for idx in range(10):\n",
    "    \n",
    "    # Select the first training example\n",
    "    example = dataset['train'][idx]\n",
    "    \n",
    "    video_frames = example['video']\n",
    "    targets = [\n",
    "        {\n",
    "            'labels': example['bboxes_labels'][i], \n",
    "            'center_points': example['bboxes_keypoints'][i], \n",
    "            'bboxes': example['bboxes'][i],\n",
    "            'track_ids': example['track_ids'][i],\n",
    "        } for i in range(20)\n",
    "    ]\n",
    "    \n",
    "    processed_frames = []\n",
    "    processed_frames_cp = []\n",
    "    processed_frames_boxes = []\n",
    "    processed_frames_boxes_cover = []\n",
    "    processed_frames_boxes_border = []\n",
    "    \n",
    "    colors = ['red', 'green', 'blue', 'yellow', 'purple', 'orange', 'pink', 'cyan', 'magenta', 'lime']\n",
    "    \n",
    "    hexs = (\n",
    "        \"042AFF\",\n",
    "        \"0BDBEB\",\n",
    "        # \"F3F3F3\", #2\n",
    "        \"00DFB7\",\n",
    "        # \"111F68\", #4\n",
    "        \"FF6FDD\",\n",
    "        \"FF444F\",\n",
    "        \"CCED00\",\n",
    "        \"00F344\",\n",
    "        \"BD00FF\",\n",
    "        \"00B4FF\",\n",
    "        \"DD00BA\",\n",
    "        \"00FFFF\",\n",
    "        \"26C000\",\n",
    "        \"01FFB3\",\n",
    "        \"7D24FF\",\n",
    "        \"7B0068\",\n",
    "        \"FF1B6C\",\n",
    "        \"FC6D2F\",\n",
    "        \"A2FF0B\",\n",
    "    )\n",
    "    \n",
    "    print(f\"Processing video with {len(video_frames)} frames...\")\n",
    "    \n",
    "    for frame_idx in range(len(video_frames)):\n",
    "        # Convert the frame to a numpy array and create a PIL Image\n",
    "        frame_np = np.array(video_frames[frame_idx])\n",
    "        # Ensure the data type is uint8 (assuming values are 0-255)\n",
    "        if frame_np.dtype != np.uint8:\n",
    "            frame_np = frame_np.astype(np.uint8)\n",
    "        frame_pil = Image.fromarray(frame_np)\n",
    "        frame_cp_pil = Image.fromarray(frame_np)\n",
    "        frame_boxes_pil = Image.fromarray(frame_np)\n",
    "        frame_boxes_cover_pil = Image.fromarray(frame_np)\n",
    "        frame_boxes_border_pil = Image.fromarray(frame_np)\n",
    "        if frame_pil.mode != \"RGB\":\n",
    "            frame_pil = frame_pil.convert(\"RGB\")\n",
    "            frame_cp_pil = frame_cp_pil.convert(\"RGB\")\n",
    "            frame_boxes_pil = frame_boxes_pil.convert(\"RGB\")\n",
    "            frame_boxes_cover_pil = frame_boxes_cover_pil.convert(\"RGB\")\n",
    "            frame_boxes_border_pil = frame_boxes_border_pil.convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(frame_pil)\n",
    "        draw_cp = ImageDraw.Draw(frame_cp_pil)\n",
    "        draw_boxes = ImageDraw.Draw(frame_boxes_pil)\n",
    "        draw_boxes_cover = ImageDraw.Draw(frame_boxes_cover_pil)\n",
    "        draw_boxes_border = ImageDraw.Draw(frame_boxes_border_pil)\n",
    "        \n",
    "        # Get the current frame's targets\n",
    "        current_target = targets[frame_idx]\n",
    "        labels = current_target['labels']\n",
    "        centers = current_target['center_points']\n",
    "        bboxes = current_target['bboxes']\n",
    "        track_ids = current_target['track_ids']\n",
    "        \n",
    "        bboxes_tensor = torch.tensor(bboxes, dtype=torch.float32)\n",
    "        \n",
    "        if bboxes_tensor.shape[0] == 0:\n",
    "            # If no bounding boxes, skip to the next frame\n",
    "            processed_frames.append(frame_pil)\n",
    "            processed_frames_cp.append(frame_cp_pil)\n",
    "            processed_frames_boxes.append(frame_boxes_pil)\n",
    "            processed_frames_boxes_cover.append(frame_boxes_cover_pil)\n",
    "            processed_frames_boxes_border.append(frame_boxes_border_pil)\n",
    "            continue\n",
    "        \n",
    "        # convert xywh to xyxy format\n",
    "        bboxes_tensor = torch.cat(\n",
    "            (bboxes_tensor[:, :2] - bboxes_tensor[:, 2:] / 2, \n",
    "             bboxes_tensor[:, :2] + bboxes_tensor[:, 2:] / 2), \n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        gt_iou_matrix = box_iou(bboxes_tensor, bboxes_tensor)\n",
    "        gt_iou_matrix.fill_diagonal_(0)\n",
    "        overlaps_exist = (gt_iou_matrix > 0.1).any(dim=1)\n",
    "        overlap_gt_indices = torch.where(overlaps_exist)[0]\n",
    "        \n",
    "        for i, (label, center, bbox, track_id) in enumerate(zip(labels, centers, bboxes, track_ids)):\n",
    "            x, y, is_visible = center\n",
    "            \n",
    "            if is_visible == 2:\n",
    "                # Convert to pixel coordinates (assuming center at 64,64)\n",
    "                pixel_x = x\n",
    "                pixel_y = y\n",
    "                \n",
    "                # Draw a red circle\n",
    "                radius = 2\n",
    "                \n",
    "                draw.ellipse(\n",
    "                    [(pixel_x - radius, pixel_y - radius),\n",
    "                     (pixel_x + radius, pixel_y + radius)],\n",
    "                    fill=f'#{hexs[track_id]}'\n",
    "                )\n",
    "                \n",
    "                draw_cp.ellipse(\n",
    "                    [(pixel_x - radius, pixel_y - radius),\n",
    "                     (pixel_x + radius, pixel_y + radius)],\n",
    "                    fill=f'#{hexs[track_id]}'\n",
    "                )\n",
    "                \n",
    "            # Draw a bounding box\n",
    "            bbox_x_min, bbox_y_min, w, h = bbox\n",
    "            bbox_x_max = bbox_x_min + w\n",
    "            bbox_y_max = bbox_y_min + h\n",
    "            draw.rectangle(\n",
    "                [bbox_x_min, bbox_y_min, bbox_x_max, bbox_y_max],\n",
    "                outline=f'#{hexs[track_id]}',\n",
    "                width=1\n",
    "            )\n",
    "            draw_boxes.rectangle(\n",
    "                [bbox_x_min, bbox_y_min, bbox_x_max, bbox_y_max],\n",
    "                outline=f'#{hexs[track_id]}',\n",
    "                width=1\n",
    "            )\n",
    "    \n",
    "            text = str(label)\n",
    "            \n",
    "            if i in overlap_gt_indices:\n",
    "                # Draw a cover box for overlapping ground truth\n",
    "                draw_boxes_cover.rectangle(\n",
    "                    [bbox_x_min, bbox_y_min, bbox_x_max, bbox_y_max],\n",
    "                    outline=f'#{hexs[track_id]}',\n",
    "                    width=1\n",
    "                )\n",
    "                draw_boxes_cover.text((bbox_x_min + 1, bbox_y_min + 1), text, fill=f'#{hexs[track_id]}')\n",
    "                \n",
    "            if bbox_x_min <= 0 or bbox_y_min <= 0 or bbox_x_max >= frame_pil.width-1 or bbox_y_max >= frame_pil.height-1:\n",
    "                draw_boxes_border.rectangle(\n",
    "                    [bbox_x_min, bbox_y_min, bbox_x_max, bbox_y_max],\n",
    "                    outline=f'#{hexs[track_id]}',\n",
    "                    width=1\n",
    "                )\n",
    "                draw_boxes_border.text((bbox_x_min + 1, bbox_y_min + 1), text, fill=f'#{hexs[track_id]}') \n",
    "            \n",
    "            # Draw the label next to the point\n",
    "            draw.text((bbox_x_min + 1, bbox_y_min + 1), text, fill=f'#{hexs[track_id]}')\n",
    "            \n",
    "            if is_visible:\n",
    "                draw_cp.text((bbox_x_min + 1, bbox_y_min + 1), text, fill=f'#{hexs[track_id]}')\n",
    "            draw_boxes.text((bbox_x_min + 1, bbox_y_min + 1), text, fill=f'#{hexs[track_id]}')\n",
    "        \n",
    "        processed_frames.append(frame_pil)\n",
    "        processed_frames_cp.append(frame_cp_pil)\n",
    "        processed_frames_boxes.append(frame_boxes_pil)\n",
    "        processed_frames_boxes_cover.append(frame_boxes_cover_pil)\n",
    "        processed_frames_boxes_border.append(frame_boxes_border_pil)\n",
    "    \n",
    "    print(f\"Processed {len(processed_frames)} frames.\")\n",
    "    \n",
    "    # Save as GIF\n",
    "    processed_frames[0].save(\n",
    "        f'./assets/annotated_video_{version}_{idx}.gif',\n",
    "        save_all=True,\n",
    "        append_images=processed_frames[1:],\n",
    "        duration=200,  # Adjust duration between frames (ms)\n",
    "        loop=0         # Loop indefinitely\n",
    "    )\n",
    "    processed_frames_cp[0].save(\n",
    "        f'./assets/annotated_video_{version}_cp_{idx}.gif',\n",
    "        save_all=True,\n",
    "        append_images=processed_frames_cp[1:],\n",
    "        duration=200,  # Adjust duration between frames (ms)\n",
    "        loop=0         # Loop indefinitely\n",
    "    )\n",
    "    processed_frames_boxes[0].save(\n",
    "        f'./assets/annotated_video_{version}_boxes_{idx}.gif',\n",
    "        save_all=True,\n",
    "        append_images=processed_frames_boxes[1:],\n",
    "        duration=200,  # Adjust duration between frames (ms)\n",
    "        loop=0         # Loop indefinitely\n",
    "    )\n",
    "    processed_frames_boxes_cover[0].save(\n",
    "        f'./assets/annotated_video_{version}_boxes_cover_{idx}.gif',\n",
    "        save_all=True,\n",
    "        append_images=processed_frames_boxes_cover[1:],\n",
    "        duration=200,  # Adjust duration between frames (ms)\n",
    "        loop=0         # Loop indefinitely\n",
    "    )\n",
    "    processed_frames_boxes_border[0].save(\n",
    "        f'./assets/annotated_video_{version}_boxes_border_{idx}.gif',\n",
    "        save_all=True,\n",
    "        append_images=processed_frames_boxes_border[1:],\n",
    "        duration=200,  # Adjust duration between frames (ms)\n",
    "        loop=0         # Loop indefinitely\n",
    "    )\n",
    "    \n",
    "    print(f\"GIF {idx} created successfully!\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimploter/miniconda3/envs/detection-moving-mnist/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 20 examples [00:00, 690.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 0 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 1 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 2 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 3 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 4 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 5 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 6 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 7 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 8 created successfully!\n",
      "Processing video with 20 frames...\n",
      "Processed 20 frames.\n",
      "GIF 9 created successfully!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2b3d9e646952c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
